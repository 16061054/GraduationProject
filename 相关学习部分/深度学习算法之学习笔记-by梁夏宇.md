# 基本知识

## 机器学习

### 机器学习定义
    Arthur Samuel:机器学习是在进行特定编程的情况下,给予计算机学习能力的领域。

    Tom Mitchell：一个程序被认为能从经验E中学习，解决任务T，达到性能度量值P。也就是说，有了经验E后，经过P评判，程序在处理T时的性能有所提升。

### 机器学习类型
    机器学习主要有两种类型，即监督学习和无监督学习。（注：早些时候——比如12年——监督学习是主流，但近年来更加倾向于探索半监督学习，这是监督学习和无监督学习的折中。）

#### 监督学习
    监督学习的基本思想是给定一个数据集，数据集中的每个样本都有相应的“正确答案”，程序通过对该数据集运用学习算法做出预测。

    监督学习主要包括回归问题和分类问题。前者是数值预测，后者是类别预测；也可以认为前者的输出值是连续的（比如商品价格、CPU利用率），而后者的输出值是离散的（种类1、种类2）。

#### 无监督学习
    无监督学习的基本思想是给定一个数据集,但该数据集没有任何的标签或只具有完全相同的标签（也就是说没有人为地给出“正确答案”），程序通过对数据集运用学习算法实现自动分类、预测等目标。聚类是无监督学习的一种。

### 机器学习算法

#### 单变量线性回归
    该算法应用于只含有一个特征或输入变量的场景。算法目标是根据给定的数据集预测出一个准确的输出值，此时的数据集被称为训练集。

    算法的表达式通常是一个线性函数，如f(x)=x0 + k*x。为衡量模型好坏，需建立代价函数，这里的x0和k作为参数，而模型所预测的值与训练集中实际值之间的差距就是建模误差，建模目标是目标便得到可以使建模误差的平方和最小的模型参数。

    最常用的代价函数是平方误差函数，常用的自动找出上述最小值的算法是梯度下降算法（得到的是局部最小值）。

#### 梯度下降
    将模型与数据集拟合时常用的算法。算法思想是随机选取一个参数组合来计算误差，然后通过梯度下降算法公式（尤其是学习率）基于当前参数和误差产生新的更接近局部最优的参数组合。

    除梯度下降之外，还有一些令代价函数最小的算法，如共轭梯度，局部优化法（BFGS），有限内存局部优化法（LBFGS）等。实际上，这些算法的收敛速度更快。

#### 多变量线性回归
    指构建含有多个输入变量、多个特征的模型对问题进行预测。

    算法的表达式同样是一个线性函数f(x)=k0*x0 + k1*x1 +...+ kn*xn，但含有n+1个参数（k0到kn）和n+1个变量（x0到xn）。可以认为模型的参数和变量均是一个n+1维向量。这里的代价函数是所有建模误差的平方和，求局部最优解同样是采用梯度下降算法，但在面对此类多维特征问题，必要时需要进行特征缩放，具体来说需要对样本数据进行某种处理或映射，使得根据数据描绘出来的图像在所有维度均较为“分散”。

    有时线性回归模型并不能很好拟合，这时可以考虑使用二次方或三次方模型等——实际上这里通过变量代换，例如y=x^3，也能转化为线性模型。具体采用什么模型，可以先根据数据画出图像，再根据图像特征来确定。

    此外，这里其实还可以运用正规方程算法，一次运算得到结果。但正规方程只适用于特征变量较少（小于1万）的线性模型，这里不详述。

#### 逻辑回归
    该算法是常用的解决分类问题的学习算法。

    对于二元逻辑回归，该算法的表达式可以理解为，以回归模型的表达式作为自变量，经逻辑函数处理，得到预测结果。即h=g(f(x))。这样做是为了得到介于0和1之间的预测值（线性模型可能产生远大于1或远小于0的值，这样的值不适合用于分类）。常用的逻辑函数是S型函数，即g(x)=1/(1+e^(-x))。

    拟合模型时，这里不能直接使用平方误差函数，因为平方误差函数在这里会得到非凸函数，可能产生较多的局部最大值或最小值，对梯度下降算法产生不良影响（可能会得到不那么好的局部最值）。因此这里使用cost(h,y)函数，其中h是上述二元逻辑回归模型提到的h(x)，y是预测分类结果。当y=1，cost(h,y)=-log(h)；当y=0，cost(h,y)=-log(1-h)。简化之后的代价函数为：cost(h,y)=-y*log(h) - (1-y)*log(1-h) 。

    拟合之前，这里同样可能需要考虑特征缩放。此外，为方便参数更新，这里更提倡使用向量化的实现，来计算h所需要的f(x)。

    对于二元逻辑回归于多元逻辑回归，可参考单变量线性回归与多变量线性回归。这里可以使用非常复杂的模型去适应具有非常复杂的形状的图像的数据。多类别分类问题（多元逻辑回归）可以归结为多个二元分类问题，基于该思想的方法也被称为“一对余”方法。

### 上述机器学习算法的缺陷及改善方法

#### 过拟合
    上述提到的机器学习算法（包括线性回归和逻辑回归）可能会出现过拟合问题。过拟合是指训练得到的模型过度拟合原始数据，而丢失了算法的本质——预测新数据。该问题出现时，模型对数据拟合较好，但预测能力较差。

    常见的解决思路是丢弃部分特征（这些特征对正确预测的贡献较小），或保留所有特征但减少参数大小（即正则化）。

#### 正则化
    正则化实际上是通过对代价函数引入正则化参数，对已有参数引入惩罚，使得拟合过程中选择较小的参数。引入方法和引入正则化参数之后的代价函数和预测函数在 http://www.ai-start.com/ml2014/html/week3.html 的7.2节有介绍，在线性回归和逻辑回归模型的运用分别在7.3和7.4节有介绍。

### 神经网络
    非线性多项式模型在多特征情况下，计算规模过于庞大（n个变量会产生n*n/2个特征），普通逻辑回归模型无法处理如此庞大的特征，故引入神经网络。神经网络最初产生的目的是制造能模拟大脑的机器，形象的说，就是“用一个单一的学习算法，去处理各种五花八门的事情”——与前述机器学习算法的不同之处在于，这些算法需要使用不同的学习算法去处理不同的事情。其背后的基本原理和出发点是，如果我们能将几乎任何传感器接入大脑，大脑的学习算法就能找出学习这些传感器数据的方法。

    大脑的神经网络是大量神经元相互链接并通过电脉冲来交流的一个网络，而人类思考的模型是神经元把自己收到的消息进行计算，并向其他神经元传递消息。由此，神经网络模型建立在很多神经元之上，每一个神经元又是一个个学习模型，这些神经元（也叫激活单元）采纳一些特征作为输出，并且根据本身的模型提供一个输出。特别之处在于，神经网络模型是分层的，是许多逻辑单元按照不同层级组织起来的网络，每一层的输出变量都是下一层的输入变量。在神经网络模型中，从左到右的算法称为前向传播算法（只是简单的输入-中间计算-输出）。神经网络模型在进行计算时可以理解为使用向量化的方法替代了前述线性回归模型中f(x)的循环计算。

    倘若只看神经网络模型的最后两层（输出层及其直接连接的层），可以发现它就像是逻辑回归模型，但其输出层直接连接的层的神经元具备更高级的特征值（由更前面的层产生），能够更好地预测新数据，这就是神经网络相对于线性回归和逻辑回归的优势。